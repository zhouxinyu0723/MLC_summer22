{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises for TensorIR"
      ],
      "metadata": {
        "id": "O-fnPFuZVAf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m  pip install mlc-ai-nightly -f https://mlc.ai/wheels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqmOOPTjVTli",
        "outputId": "60326deb-7540-406c-fea5-059d13620280"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-nightly\n",
            "  Downloading https://github.com/mlc-ai/utils/releases/download/v0.9.dev0/mlc_ai_nightly-0.9.dev2972%2Bg78908c2ea-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.8 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from mlc-ai-nightly) (5.4.8)\n",
            "Collecting synr==0.6.0\n",
            "  Downloading synr-0.6.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from mlc-ai-nightly) (1.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mlc-ai-nightly) (1.21.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from mlc-ai-nightly) (22.1.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.8/dist-packages (from mlc-ai-nightly) (6.0.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from mlc-ai-nightly) (4.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from mlc-ai-nightly) (1.7.3)\n",
            "Installing collected packages: synr, mlc-ai-nightly\n",
            "Successfully installed mlc-ai-nightly-0.9.dev2972+g78908c2ea synr-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import tir as T\n",
        "import numpy as np\n",
        "import IPython"
      ],
      "metadata": {
        "id": "s1_mb5G-VFAo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 1: How to Write TensorIR\n",
        "In this section, let's try to write TensorIR manually according to high-level instructions (e.g., Numpy or Torch). First, we give an example of element-wise add function, to show what should we do to write a TensorIR function.\n",
        "\n",
        "#### Example: Element-wise Add\n",
        "First, let's try to use Numpy to write an element-wise add function."
      ],
      "metadata": {
        "id": "DLrcFq5VVGv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init data\n",
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(16, 0, -1).reshape(4, 4)"
      ],
      "metadata": {
        "id": "MeJ95Hu-Vdvf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy version\n",
        "c_np = a + b\n",
        "c_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QhY3pe8Vh8Q",
        "outputId": "b7a848b3-44e1-4373-b9b4-d359247f30ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we directly write TensorIR, we should first translate high-level computation abstraction (e.g., ndarray + ndarray) to low-level python implementation (standard for loops with element access and operation)\n",
        "\n",
        "Notably, the initial value of the o utput array (or buffer) is not always 0. We need to write or initialize it in our implementation, which is important for reduction operator (e.g. matmul and conv)"
      ],
      "metadata": {
        "id": "iQhDZb9EVmOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# low-level numpy version\n",
        "def lnumpy_add(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      c[i, j] = a[i, j] + b[i, j]\n",
        "c_lnumpy = np.empty((4, 4), dtype=np.int64)\n",
        "lnumpy_add(a, b, c_lnumpy)\n",
        "c_lnumpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_MSPL3_VnbQ",
        "outputId": "b7abdfa7-f94f-4ef0-a6cf-166592cec521"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's take a further step: translate low-level NumPy implementation into TensorIR. And compare the result with it comes from NumPy."
      ],
      "metadata": {
        "id": "gmymbQQnWAhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorIR version\n",
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer[(4, 4), \"int64\"],\n",
        "          B: T.Buffer[(4, 4), \"int64\"],\n",
        "          C: T.Buffer[(4, 4), \"int64\"]):\n",
        "    T.func_attr({\"global_symbol\": \"add\"})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
        "\n",
        "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
      ],
      "metadata": {
        "id": "olS28OVDWBsm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we have finished the TensorIR function. Please take your time to finish the following exercises\n",
        "\n",
        "#### Exercise 1: Broadcast Add\n",
        "Please write a TensorIR function that adds two arrays with broadcasting."
      ],
      "metadata": {
        "id": "Lw4sHuEoWDl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init data\n",
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(4, 0, -1).reshape(4)"
      ],
      "metadata": {
        "id": "JDil3eFGWNt7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy version\n",
        "c_np = a + b\n",
        "c_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n8ZGHGDWQ0w",
        "outputId": "db194eed-3ff1-46ed-c522-af32019737c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  4,  4,  4],\n",
              "       [ 8,  8,  8,  8],\n",
              "       [12, 12, 12, 12],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KK = 4\n",
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer[(KK,KK), 'int64'],\n",
        "       B: T.Buffer[(KK), 'int64'],\n",
        "       C: T.Buffer[(KK,KK), 'int64']):\n",
        "    T.func_attr({\"global_symbol\": \"add\", \"tir.noalias\": True})\n",
        "    # TODO\n",
        "    for i, j in T.grid(KK, KK):\n",
        "      with T.block(\"Y\"):\n",
        "        pass"
      ],
      "metadata": {
        "id": "pMyVLs0gjmtM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please complete the following Module `MyAdd` and run the code to check your implementation."
      ],
      "metadata": {
        "id": "3HjDiDsxWStJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer[(4,4), 'int64'],\n",
        "       B: T.Buffer[(4), 'int64'],\n",
        "       C: T.Buffer[(4,4), 'int64'],):\n",
        "    T.func_attr({\"global_symbol\": \"add\", \"tir.noalias\": True})\n",
        "    # TODO\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vj]\n",
        "\n",
        "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
      ],
      "metadata": {
        "id": "tJp19VZKWVcb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 2: 2D Convolution\n",
        "Then, let's try to do something challenging: 2D convolution, which is a common operation in image processing.\n",
        "\n",
        "Here is the mathematical definition of convolution with NCHW layout:\n",
        "\n",
        "$$Conv[b, p, i, j] = \\sum_{di, dj, q} A[b, q, strides * i + di, strides * j + dj] * W[p, q, di, dj]$$ , where, $A$ is the input tensor, $W$ is the weight tensor, $b$ is the batch index, $p$ is the out channels, $i$ and $j$ are indices for image hight and width, $d_i$ and $d_j$ are the indices of the weight, $q$ is the input channel, and strides is the stride of the filter window.\n",
        "\n",
        "In the exercise, we pick a small and simple case with stride=1, padding=0."
      ],
      "metadata": {
        "id": "dojP-Z1xXHCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
        "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
        "data = np.arange(N*CI*H*W).reshape(N, CI, H, W)\n",
        "weight = np.arange(CO*CI*K*K).reshape(CO, CI, K, K)"
      ],
      "metadata": {
        "id": "rXBKgIBBXVcu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch version\n",
        "import torch\n",
        "data_torch = torch.Tensor(data)\n",
        "weight_torch = torch.Tensor(weight)\n",
        "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
        "conv_torch = conv_torch.numpy().astype(np.int64)\n",
        "conv_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px80bKdmXY0X",
        "outputId": "becc5664-b527-43a1-dd4f-ef946974c9c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 474,  510,  546,  582,  618,  654],\n",
              "         [ 762,  798,  834,  870,  906,  942],\n",
              "         [1050, 1086, 1122, 1158, 1194, 1230],\n",
              "         [1338, 1374, 1410, 1446, 1482, 1518],\n",
              "         [1626, 1662, 1698, 1734, 1770, 1806],\n",
              "         [1914, 1950, 1986, 2022, 2058, 2094]],\n",
              "\n",
              "        [[1203, 1320, 1437, 1554, 1671, 1788],\n",
              "         [2139, 2256, 2373, 2490, 2607, 2724],\n",
              "         [3075, 3192, 3309, 3426, 3543, 3660],\n",
              "         [4011, 4128, 4245, 4362, 4479, 4596],\n",
              "         [4947, 5064, 5181, 5298, 5415, 5532],\n",
              "         [5883, 6000, 6117, 6234, 6351, 6468]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please complete the following Module MyConv and run the code to check your implementation."
      ],
      "metadata": {
        "id": "6kcNLURmXcnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyConv:\n",
        "  @T.prim_func\n",
        "  def conv(A: T.Buffer[(N, CI, H, W), 'int64'],\n",
        "        B: T.Buffer[(CO, CI, K, K), 'int64'],\n",
        "        C: T.Buffer[(N, CO, OUT_H, OUT_W), 'int64'],):\n",
        "    T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
        "    # TODO\n",
        "    for bb, p, i, j, q, di, dj in T.grid(N, CO, OUT_H, OUT_W, CI, K, K):\n",
        "      with T.block(\"Y\"):\n",
        "        vbb = T.axis.spatial(N, bb)\n",
        "        vp = T.axis.spatial(CO, p)\n",
        "        vi = T.axis.spatial(OUT_H, i)\n",
        "        vj = T.axis.spatial(OUT_W, j)\n",
        "        vq = T.axis.reduce(CI, q)\n",
        "        vdi = T.axis.reduce(K, di)\n",
        "        vdj = T.axis.reduce(K, dj)\n",
        "        C[vbb, vp, vi, vj] = C[vbb, vp, vi, vj] + A[vbb, vq, vi+vdi, vj+vdj] * B[vp, vq, vdi, vdj]\n",
        "        \n",
        "\n",
        "\n",
        "#rt_lib = tvm.build(MyConv, target=\"llvm\")\n",
        "#data_tvm = tvm.nd.array(data)\n",
        "#weight_tvm = tvm.nd.array(weight)\n",
        "#conv_tvm = tvm.nd.array(np.empty((N, CO, OUT_H, OUT_W), dtype=np.int64))\n",
        "#rt_lib[\"conv\"](data_tvm, weight_tvm, conv_tvm)\n",
        "#np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
      ],
      "metadata": {
        "id": "IcDxn96qXdKr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5.2. Section 2: How to Transform TensorIR\n",
        "In the lecture, we learned that TensorIR is not only a programming language but also an abstraction for program transformation. In this section, let’s try to transform the program. We take bmm_relu (batched_matmul_relu) in our studies, which is a variant of operations that common appear in models such as transformers.\n",
        "\n",
        "#### 2.5.2.1. Parallel, Vectorize and Unroll\n",
        "First, we introduce some new primitives, parallel, vectorize and unroll. These three primitives operates on loops to indicate how this loop execute. Here is the example:"
      ],
      "metadata": {
        "id": "GY9-7pxXPB45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer[(4, 4), \"int64\"],\n",
        "          B: T.Buffer[(4, 4), \"int64\"],\n",
        "          C: T.Buffer[(4, 4), \"int64\"]):\n",
        "    T.func_attr({\"global_symbol\": \"add\"})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
        "\n",
        "sch = tvm.tir.Schedule(MyAdd)\n",
        "block = sch.get_block(\"C\", func_name=\"add\")\n",
        "i, j = sch.get_loops(block)\n",
        "i0, i1 = sch.split(i, factors=[2, 2])\n",
        "sch.parallel(i0)\n",
        "sch.unroll(i1)\n",
        "sch.vectorize(j)\n",
        "IPython.display.Code(sch.mod.script(), language=\"python\")"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/undefined": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "ndzGev2DPE-e",
        "outputId": "05a7acb4-3023-46f0-9843-2d3f790ce29d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "@tvm.script.ir_module\n",
              "class Module:\n",
              "    @T.prim_func\n",
              "    def add(A: T.Buffer[(4, 4), \"int64\"], B: T.Buffer[(4, 4), \"int64\"], C: T.Buffer[(4, 4), \"int64\"]):\n",
              "        # function attr dict\n",
              "        T.func_attr({\"global_symbol\": \"add\"})\n",
              "        # body\n",
              "        # with T.block(\"root\")\n",
              "        for i_0 in T.parallel(2):\n",
              "            for i_1 in T.unroll(2):\n",
              "                for j in T.vectorized(4):\n",
              "                    with T.block(\"C\"):\n",
              "                        vi = T.axis.spatial(4, i_0 * 2 + i_1)\n",
              "                        vj = T.axis.spatial(4, j)\n",
              "                        T.reads(A[vi, vj], B[vi, vj])\n",
              "                        T.writes(C[vi, vj])\n",
              "                        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
              "    "
            ],
            "text/html": [
              "<style>.output_html .hll { background-color: #ffffcc }\n",
              ".output_html  { background: #f8f8f8; }\n",
              ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
              ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
              ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
              ".output_html .o { color: #666666 } /* Operator */\n",
              ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
              ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
              ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
              ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
              ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
              ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
              ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
              ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
              ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
              ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
              ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
              ".output_html .go { color: #888888 } /* Generic.Output */\n",
              ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
              ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
              ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
              ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
              ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
              ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
              ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
              ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
              ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
              ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
              ".output_html .m { color: #666666 } /* Literal.Number */\n",
              ".output_html .s { color: #BA2121 } /* Literal.String */\n",
              ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
              ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
              ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
              ".output_html .no { color: #880000 } /* Name.Constant */\n",
              ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
              ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
              ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
              ".output_html .nf { color: #0000FF } /* Name.Function */\n",
              ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
              ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
              ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
              ".output_html .nv { color: #19177C } /* Name.Variable */\n",
              ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
              ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
              ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
              ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
              ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
              ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
              ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
              ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
              ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
              ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
              ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
              ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
              ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
              ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
              ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
              ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
              ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
              ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
              ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
              ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
              ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
              ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
              ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
              ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
              ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
              ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
              ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
              "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
              "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">add</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">],</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;int64&quot;</span><span class=\"p\">]):</span>\n",
              "        <span class=\"c1\"># function attr dict</span>\n",
              "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;add&quot;</span><span class=\"p\">})</span>\n",
              "        <span class=\"c1\"># body</span>\n",
              "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">i_0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">parallel</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n",
              "            <span class=\"k\">for</span> <span class=\"n\">i_1</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">unroll</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">):</span>\n",
              "                <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">vectorized</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">):</span>\n",
              "                    <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
              "                        <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">i_0</span> <span class=\"o\">*</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"n\">i_1</span><span class=\"p\">)</span>\n",
              "                        <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">)</span>\n",
              "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
              "    \n",
              "</pre></div>\n"
            ],
            "text/latex": "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n\\PY{n+nd}{@tvm}\\PY{o}{.}\\PY{n}{script}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n    \\PY{k}{def} \\PY{n+nf}{add}\\PY{p}{(}\\PY{n}{A}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{C}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{int64}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n        \\PY{c+c1}{\\PYZsh{} function attr dict}\n        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{add}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n        \\PY{c+c1}{\\PYZsh{} body}\n        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n        \\PY{k}{for} \\PY{n}{i\\PYZus{}0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{parallel}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{:}\n            \\PY{k}{for} \\PY{n}{i\\PYZus{}1} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{unroll}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{:}\n                \\PY{k}{for} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{vectorized}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                        \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{n}{i\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{2} \\PY{o}{+} \\PY{n}{i\\PYZus{}1}\\PY{p}{)}\n                        \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{,} \\PY{n}{j}\\PY{p}{)}\n                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{C}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n    \n\\end{Verbatim}\n"
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.5.2.2. Exercise 3: Transform a batch matmul program\n",
        "Now, let's go back to the `bmm_relu` exercise. First, Let's see the definition of `bmm`:\n",
        "\n",
        "- $Y_{n, i, j} = \\sum_k A_{n, i, k} \\times B_{n, k, j}$\n",
        "- $C_{n, i, j} = \\mathbb{relu}(Y_{n,i,j}) = \\mathbb{max}(Y_{n, i, j}, 0)$\n",
        "\n",
        "It's your time to write the TensorIR for `bmm_relu`. We provide the lnumpy func as hint:\n"
      ],
      "metadata": {
        "id": "_H8RKq4CPnVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lnumpy_mm_relu_v2(A: np.ndarray, B: np.ndarray, C: np.ndarray):\n",
        "  Y = np.empty((16, 128, 128), dtype=\"float32\")\n",
        "  for n in range(16):\n",
        "    for i in range(128):\n",
        "      for j in range(128):\n",
        "        for k in range(128):\n",
        "          if k == 0:\n",
        "              Y[n, i, j] = 0\n",
        "          Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
        "  for n in range(16):\n",
        "    for i in range(128):\n",
        "      for j in range(128):\n",
        "        C[n, i, j] = max(Y[n, i, j], 0)"
      ],
      "metadata": {
        "id": "ozIAgSjAQt9f"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyBmmRelu:\n",
        "  @T.prim_func\n",
        "  def bmm_relu( A: T.Buffer[(16, 128, 128), 'float32'],\n",
        "          B: T.Buffer[(16, 128, 128), 'float32'],\n",
        "          C: T.Buffer[(16, 128, 128), 'float32']):\n",
        "    T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
        "    Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
        "    for n, i, j, k in T.grid(16, 128, 128, 128):\n",
        "      with T.block(\"Y\"):\n",
        "        vn, vi, vj, vk = T.axis.remap(\"SSSR\", [n, i, j, k])\n",
        "        with T.init():\n",
        "          Y[vn, vi, vj] = T.float32(0)\n",
        "        Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * A[vn, vk, vj]\n",
        "    for n, i, j in T.grid(16, 128, 128):\n",
        "      with T.block(\"C\"):\n",
        "        vn, vi, vj = T.axis.remap(\"SSS\", [n, i, j])\n",
        "        C[vn, vi, vj] = T.max(Y[vn, vi, vj], 0)\n",
        "\n",
        "sch = tvm.tir.Schedule(MyBmmRelu)\n",
        "IPython.display.Code(sch.mod.script(), language=\"python\")\n",
        "# Also please validate your result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "yTIsfIABRFU4",
        "outputId": "e6b9aa78-396e-4b29-8fe3-6035f5c6bc3f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "@tvm.script.ir_module\n",
              "class Module:\n",
              "    @T.prim_func\n",
              "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
              "        # function attr dict\n",
              "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"bmm_relu\"})\n",
              "        # body\n",
              "        # with T.block(\"root\")\n",
              "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
              "        for n, i, j, k in T.grid(16, 128, 128, 128):\n",
              "            with T.block(\"Y\"):\n",
              "                vn, vi, vj, vk = T.axis.remap(\"SSSR\", [n, i, j, k])\n",
              "                T.reads(A[vn, T.min(vi, vk) : T.max(vi, vk) + 1, T.min(vk, vj) : T.max(vk, vj) + 1])\n",
              "                T.writes(Y[vn, vi, vj])\n",
              "                with T.init():\n",
              "                    Y[vn, vi, vj] = T.float32(0)\n",
              "                Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * A[vn, vk, vj]\n",
              "        for n, i, j in T.grid(16, 128, 128):\n",
              "            with T.block(\"C\"):\n",
              "                vn, vi, vj = T.axis.remap(\"SSS\", [n, i, j])\n",
              "                T.reads(Y[vn, vi, vj])\n",
              "                T.writes(C[vn, vi, vj])\n",
              "                C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
              "    "
            ],
            "text/html": [
              "<style>.output_html .hll { background-color: #ffffcc }\n",
              ".output_html  { background: #f8f8f8; }\n",
              ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
              ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
              ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
              ".output_html .o { color: #666666 } /* Operator */\n",
              ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
              ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
              ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
              ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
              ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
              ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
              ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
              ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
              ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
              ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
              ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
              ".output_html .go { color: #888888 } /* Generic.Output */\n",
              ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
              ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
              ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
              ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
              ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
              ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
              ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
              ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
              ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
              ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
              ".output_html .m { color: #666666 } /* Literal.Number */\n",
              ".output_html .s { color: #BA2121 } /* Literal.String */\n",
              ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
              ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
              ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
              ".output_html .no { color: #880000 } /* Name.Constant */\n",
              ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
              ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
              ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
              ".output_html .nf { color: #0000FF } /* Name.Function */\n",
              ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
              ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
              ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
              ".output_html .nv { color: #19177C } /* Name.Variable */\n",
              ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
              ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
              ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
              ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
              ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
              ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
              ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
              ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
              ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
              ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
              ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
              ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
              ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
              ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
              ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
              ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
              ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
              ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
              ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
              ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
              ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
              ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
              ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
              ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
              ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
              ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
              ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
              "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
              "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">bmm_relu</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
              "        <span class=\"c1\"># function attr dict</span>\n",
              "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;bmm_relu&quot;</span><span class=\"p\">})</span>\n",
              "        <span class=\"c1\"># body</span>\n",
              "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
              "        <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
              "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
              "                <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSSR&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">])</span>\n",
              "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">min</span><span class=\"p\">(</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">min</span><span class=\"p\">(</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">])</span>\n",
              "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
              "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
              "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
              "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
              "                <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
              "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
              "    \n",
              "</pre></div>\n"
            ],
            "text/latex": "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n\\PY{n+nd}{@tvm}\\PY{o}{.}\\PY{n}{script}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n    \\PY{k}{def} \\PY{n+nf}{bmm\\PYZus{}relu}\\PY{p}{(}\\PY{n}{A}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{C}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n        \\PY{c+c1}{\\PYZsh{} function attr dict}\n        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{bmm\\PYZus{}relu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n        \\PY{c+c1}{\\PYZsh{} body}\n        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n        \\PY{n}{Y} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{]}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n        \\PY{k}{for} \\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSSR}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k}\\PY{p}{]}\\PY{p}{)}\n                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{min}\\PY{p}{(}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{)} \\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{)} \\PY{o}{+} \\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{min}\\PY{p}{(}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{)} \\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{)} \\PY{o}{+} \\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{)}\n                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n        \\PY{k}{for} \\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                \\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n    \n\\end{Verbatim}\n"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, let’s focus on transform the original program to a specific target. Note that the target program may not be the best one due to different hardware. But this exercise aims to let students understand how to transform the program to a wanted one. Here is the target program:\n",
        "\n",
        "```\n",
        "@tvm.script.ir_module\n",
        "class TargetModule:\n",
        "    @T.prim_func\n",
        "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
        "        T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
        "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
        "        for i0 in T.parallel(16):\n",
        "            for i1, i2_0 in T.grid(128, 16):\n",
        "                for ax0_init in T.vectorized(8):\n",
        "                    with T.block(\"Y_init\"):\n",
        "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                        j = T.axis.spatial(128, i2_0 * 8 + ax0_init)\n",
        "                        Y[n, i, j] = T.float32(0)\n",
        "                for ax1_0 in T.serial(32):\n",
        "                    for ax1_1 in T.unroll(4):\n",
        "                        for ax0 in T.serial(8):\n",
        "                            with T.block(\"Y_update\"):\n",
        "                                n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                                j = T.axis.spatial(128, i2_0 * 8 + ax0)\n",
        "                                k = T.axis.reduce(128, ax1_0 * 4 + ax1_1)\n",
        "                                Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
        "                for i2_1 in T.vectorized(8):\n",
        "                    with T.block(\"C\"):\n",
        "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
        "                        j = T.axis.spatial(128, i2_0 * 8 + i2_1)\n",
        "                        C[n, i, j] = T.max(Y[n, i, j], T.float32(0))\n",
        "```\n",
        "Your task is to transform the original program to the target program.\n"
      ],
      "metadata": {
        "id": "NL2GbZTUTtKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sch = tvm.tir.Schedule(MyBmmRelu)\n",
        "# TODO: transformations\n",
        "# Hints: you can use\n",
        "# `IPython.display.Code(sch.mod.script(), language=\"python\")`\n",
        "# or `print(sch.mod.script())`\n",
        "# to show the current program at any time during the transformation.\n",
        "\n",
        "# Step 1. Get blocks\n",
        "Y = sch.get_block(\"Y\", func_name=\"bmm_relu\")\n",
        "C = sch.get_block(\"C\", func_name=\"bmm_relu\")\n",
        "\n",
        "# Step 2. Get loops\n",
        "n, i, j, k = sch.get_loops(Y)\n",
        "\n",
        "# Step 3. Organize the loops\n",
        "j0, j1 = sch.split(j, factors=[None, 8])\n",
        "k0, k1 = sch.split(k, factors=[None, 4])\n",
        "sch.reorder(n, i, j0, k0, k1, j1)\n",
        "# sch.compute_at/reverse_compute_at(...)\n",
        "sch.reverse_compute_at(C, j0)\n",
        "\n",
        "# Step 4. decompose reduction\n",
        "Y_init = sch.decompose_reduction(Y, k0)\n",
        "\n",
        "# Step 5. vectorize / parallel / unroll\n",
        "# sch.vectorize(...)\n",
        "# sch.parallel(...)\n",
        "# sch.unroll(...)\n",
        "\n",
        "IPython.display.Code(sch.mod.script(), language=\"python\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "CybiwIwVT5BR",
        "outputId": "841b18f3-e879-4dc7-d8c5-3af3acd9b26c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "@tvm.script.ir_module\n",
              "class Module:\n",
              "    @T.prim_func\n",
              "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
              "        # function attr dict\n",
              "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"bmm_relu\"})\n",
              "        # body\n",
              "        # with T.block(\"root\")\n",
              "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
              "        for n, i, j_0 in T.grid(16, 128, 16):\n",
              "            for j_1_init in T.serial(8):\n",
              "                with T.block(\"Y_init\"):\n",
              "                    vn, vi = T.axis.remap(\"SS\", [n, i])\n",
              "                    vj = T.axis.spatial(128, j_0 * 8 + j_1_init)\n",
              "                    T.reads()\n",
              "                    T.writes(Y[vn, vi, vj])\n",
              "                    Y[vn, vi, vj] = T.float32(0)\n",
              "            for k_0, k_1, j_1 in T.grid(32, 4, 8):\n",
              "                with T.block(\"Y_update\"):\n",
              "                    vn, vi = T.axis.remap(\"SS\", [n, i])\n",
              "                    vj = T.axis.spatial(128, j_0 * 8 + j_1)\n",
              "                    vk = T.axis.reduce(128, k_0 * 4 + k_1)\n",
              "                    T.reads(Y[vn, vi, vj], A[vn, T.min(vi, vk) : T.max(vi, vk) + 1, T.min(vk, vj) : T.max(vk, vj) + 1])\n",
              "                    T.writes(Y[vn, vi, vj])\n",
              "                    Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * A[vn, vk, vj]\n",
              "            for ax0 in T.serial(8):\n",
              "                with T.block(\"C\"):\n",
              "                    vn, vi = T.axis.remap(\"SS\", [n, i])\n",
              "                    vj = T.axis.spatial(128, j_0 * 8 + ax0)\n",
              "                    T.reads(Y[vn, vi, vj])\n",
              "                    T.writes(C[vn, vi, vj])\n",
              "                    C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
              "    "
            ],
            "text/html": [
              "<style>.output_html .hll { background-color: #ffffcc }\n",
              ".output_html  { background: #f8f8f8; }\n",
              ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
              ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
              ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
              ".output_html .o { color: #666666 } /* Operator */\n",
              ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
              ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
              ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
              ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
              ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
              ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
              ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
              ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
              ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
              ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
              ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
              ".output_html .go { color: #888888 } /* Generic.Output */\n",
              ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
              ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
              ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
              ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
              ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
              ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
              ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
              ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
              ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
              ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
              ".output_html .m { color: #666666 } /* Literal.Number */\n",
              ".output_html .s { color: #BA2121 } /* Literal.String */\n",
              ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
              ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
              ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
              ".output_html .no { color: #880000 } /* Name.Constant */\n",
              ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
              ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
              ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
              ".output_html .nf { color: #0000FF } /* Name.Function */\n",
              ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
              ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
              ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
              ".output_html .nv { color: #19177C } /* Name.Variable */\n",
              ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
              ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
              ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
              ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
              ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
              ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
              ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
              ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
              ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
              ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
              ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
              ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
              ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
              ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
              ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
              ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
              ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
              ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
              ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
              ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
              ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
              ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
              ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
              ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
              ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
              ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
              ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
              "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
              "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">bmm_relu</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
              "        <span class=\"c1\"># function attr dict</span>\n",
              "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;bmm_relu&quot;</span><span class=\"p\">})</span>\n",
              "        <span class=\"c1\"># body</span>\n",
              "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
              "        <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">):</span>\n",
              "            <span class=\"k\">for</span> <span class=\"n\">j_1_init</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">serial</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">):</span>\n",
              "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y_init&quot;</span><span class=\"p\">):</span>\n",
              "                    <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
              "                    <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j_1_init</span><span class=\"p\">)</span>\n",
              "                    <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">()</span>\n",
              "                    <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
              "            <span class=\"k\">for</span> <span class=\"n\">k_0</span><span class=\"p\">,</span> <span class=\"n\">k_1</span><span class=\"p\">,</span> <span class=\"n\">j_1</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">):</span>\n",
              "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y_update&quot;</span><span class=\"p\">):</span>\n",
              "                    <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
              "                    <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j_1</span><span class=\"p\">)</span>\n",
              "                    <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">reduce</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">k_0</span> <span class=\"o\">*</span> <span class=\"mi\">4</span> <span class=\"o\">+</span> <span class=\"n\">k_1</span><span class=\"p\">)</span>\n",
              "                    <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">min</span><span class=\"p\">(</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">min</span><span class=\"p\">(</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">)</span> <span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">])</span>\n",
              "                    <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
              "            <span class=\"k\">for</span> <span class=\"n\">ax0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">serial</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">):</span>\n",
              "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
              "                    <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
              "                    <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">ax0</span><span class=\"p\">)</span>\n",
              "                    <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                    <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                    <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
              "    \n",
              "</pre></div>\n"
            ],
            "text/latex": "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n\\PY{n+nd}{@tvm}\\PY{o}{.}\\PY{n}{script}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n    \\PY{k}{def} \\PY{n+nf}{bmm\\PYZus{}relu}\\PY{p}{(}\\PY{n}{A}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{C}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n        \\PY{c+c1}{\\PYZsh{} function attr dict}\n        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{bmm\\PYZus{}relu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n        \\PY{c+c1}{\\PYZsh{} body}\n        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n        \\PY{n}{Y} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{]}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n        \\PY{k}{for} \\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{16}\\PY{p}{)}\\PY{p}{:}\n            \\PY{k}{for} \\PY{n}{j\\PYZus{}1\\PYZus{}init} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{serial}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{)}\\PY{p}{:}\n                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y\\PYZus{}init}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{]}\\PY{p}{)}\n                    \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{8} \\PY{o}{+} \\PY{n}{j\\PYZus{}1\\PYZus{}init}\\PY{p}{)}\n                    \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{p}{)}\n                    \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                    \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n            \\PY{k}{for} \\PY{n}{k\\PYZus{}0}\\PY{p}{,} \\PY{n}{k\\PYZus{}1}\\PY{p}{,} \\PY{n}{j\\PYZus{}1} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{8}\\PY{p}{)}\\PY{p}{:}\n                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y\\PYZus{}update}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{]}\\PY{p}{)}\n                    \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{8} \\PY{o}{+} \\PY{n}{j\\PYZus{}1}\\PY{p}{)}\n                    \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{reduce}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{k\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{4} \\PY{o}{+} \\PY{n}{k\\PYZus{}1}\\PY{p}{)}\n                    \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{min}\\PY{p}{(}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{)} \\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{)} \\PY{o}{+} \\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{min}\\PY{p}{(}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{)} \\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{)} \\PY{o}{+} \\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{)}\n                    \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                    \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n            \\PY{k}{for} \\PY{n}{ax0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{serial}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{)}\\PY{p}{:}\n                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{]}\\PY{p}{)}\n                    \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{8} \\PY{o}{+} \\PY{n}{ax0}\\PY{p}{)}\n                    \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                    \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                    \\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n    \n\\end{Verbatim}\n"
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTIONAL If we want to make sure the transformed program is exactly the same as the given target, we can use assert_structural_equal. Note that this step is an optional step in this exercise. It’s good enough if you transformed the program towards the target and get performance improvement.\n",
        "\n",
        "tvm.ir.assert_structural_equal(sch.mod, TargetModule)\n",
        "print(\"Pass\")\n",
        "Copy to clipboard\n",
        "#### 2.5.2.3. Build and Evaluate\n",
        "Finally we can evaluate the performance of the transformed program."
      ],
      "metadata": {
        "id": "XEKa21zsT6yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "before_rt_lib = tvm.build(MyBmmRelu, target=\"llvm\")\n",
        "after_rt_lib = tvm.build(sch.mod, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "b_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "c_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "after_rt_lib[\"bmm_relu\"](a_tvm, b_tvm, c_tvm)\n",
        "before_timer = before_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
        "print(\"Before transformation:\")\n",
        "print(before_timer(a_tvm, b_tvm, c_tvm))\n",
        "\n",
        "f_timer = after_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
        "print(\"After transformation:\")\n",
        "print(f_timer(a_tvm, b_tvm, c_tvm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_ulRfa6UEUT",
        "outputId": "b350e619-f667-4437-d50d-57f7805af32f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before transformation:\n",
            "Execution time summary:\n",
            " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
            "  65.0827      65.0827      65.0827      65.0827       0.0000   \n",
            "               \n",
            "After transformation:\n",
            "Execution time summary:\n",
            " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
            "   6.1972       6.1972       6.1972       6.1972       0.0000   \n",
            "               \n"
          ]
        }
      ]
    }
  ]
}